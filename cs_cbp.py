# -*- coding: utf-8 -*-
"""CS_CBP.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HGYsXqb_xWzjAq6FDtFuiTVcpc0uZG_G
"""

import pandas as pd
from google.colab import files
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from statsmodels.tsa.seasonal import STL
from scipy.integrate import solve_ivp

uploaded = files.upload()

#Reading data using pandas
data = pd.read_csv("Infectious Disease 2001-2014.csv")

#First 5 rows of Infectious DataSet
data.head()

#Info about the dataSet
data.info()

# Shape of the DataSet (no.of rows & columns)
data.shape

# Describing the dataSet
data.describe()

# Columns present in the dataSet
data.columns

# DataType of each column
data.dtypes

"""# Cleaning Infectious dataSet by removing missing values & duplicate values"""

#Checking rows with missing values

missing_values_rows = data.isnull().any(axis=1)
print("Rows with missing values")
print(missing_values_rows)

#Checking rows with duplicate values

duplicate_rows = data[data.duplicated()]
print("Duplicated Rows")
print(duplicate_rows)

# In case if there is any missing or duplicate values
data.dropna(axis = 0,inplace = True)
data.drop_duplicates(inplace = True)
data.to_csv("cleaned_dataset.csv",index = False)

file_path = "cleaned_dataset.csv"
files.download(file_path)

"""# Detecting Potential Outliers with Z Score"""

# Potential Outliers are the values which are too extreme /  It can be too high or too low
# Z-score is a statistical measurement that describes a values's relationship to the mean of group of values

data.head()

columns_to_check = ["Count","Rate"]

# The data points with Z scores greater than or less than 3 will be considered as potential outliers

outlier_threshold = 3

# Detecting potential outliers for Count

count_z_score = np.abs((data["Count"] - data["Count"].mean()) / data["Count"].std())
count_outlier_mask = count_z_score > outlier_threshold
potential_count_outliers = data[count_outlier_mask]
print("Potential Count Outliers:")
print(potential_count_outliers)

# Detecting potential outliers for Rate

rate_z_score = np.abs((data["Rate"] - data["Rate"].mean()) / data["Rate"].std())
rate_outlier_mask = rate_z_score > outlier_threshold
potential_rate_outliers = data[rate_outlier_mask]
print("Potential Rate Outliers:")
print(potential_rate_outliers)

"""# Finding Correlation between Population & Disease Rate"""

correlation_coefficient = data["Population"].corr(data["Rate"])

print(f'Correlation Coefficient:{correlation_coefficient:.2f}')

# Scatter plot to visualize the correlation between Population & Disease Rate

plt.figure(figsize = (8,6))
plt.scatter(data["Population"],data["Rate"],alpha = 0.5)
plt.xlabel("Population")
plt.ylabel("Disease Rate")
plt.title("Population vs Disease Rate")
plt.text(0.1,0.9,f'Correlation:{correlation_coefficient:.2f}',transform = plt.gca().transAxes)
plt.show()

"""# Analyzing infected patients Demographics"""

data.head()

# Analying Top 5 Diseases in each of the gender

data = data[data["Sex"].isin(["Male","Female"])]

grouped_data = data.groupby(["Sex"])[["Count","Rate"]].sum()

top_diseases = {}
for sex in grouped_data.index:
  subset = data[data["Sex"]==sex]
  subset = subset.drop_duplicates(subset=["Disease"])
  top_diseases[sex] = subset[["Disease","Rate"]].nlargest(5,"Rate")

for sex, top_disease_df in top_diseases.items():
  print(f"Top 5 Diseases for {sex}:")
  print(top_disease_df)

# Visualizing the above data using Bar Chart

for sex, top_disease_df in top_diseases.items():
  plt.figure(figsize = (10,6))
  plt.barh(top_disease_df["Disease"],top_disease_df["Rate"])
  plt.xlabel("Rate")
  plt.title(f"Top 5 Diseases for {sex}")
  plt.gca().invert_yaxis()
  plt.show

"""# Mapping Infectious Disease per Country with Heatmap"""

# Total no.of countries present in the dataSet

count_county = data["County"].nunique()
print(f"Number of Countries : {count_county}")

grouped_data = data.groupby(["County","Disease"]).agg({"Count":"sum","Rate":"mean","Population":"mean"}).reset_index()

top_disease_per_county = grouped_data.loc[grouped_data.groupby("County")["Count"].idxmax()]

print(top_disease_per_county[["County","Disease","Count","Rate","Population"]])

heatmap_data = top_disease_per_county.pivot("County","Disease","Count")
plt.figure(figsize = (12,8))
sns.heatmap(heatmap_data, annot = True, fmt = ".0f", cmap = "YlGnBu", cbar_kws = {"label":"Count"})
plt.title("Top Diseases per Country")
plt.show()

"""# Analyzing Infectious Disease Yearly Trend"""

# Top 3 diseases in every year with the no.of people effected

grouped_data = data.groupby(["Year","Disease"])[["Count"]].sum()

top_disease_count = grouped_data.groupby("Year",group_keys=False).apply(lambda x: x.nlargest(3,"Count"))

for year in grouped_data.index.get_level_values("Year").unique():
  top_count_disease = top_disease_count[top_disease_count.index.get_level_values("Year")==year]
  print(f"Top 3 Diseases by Count for {year}")
  for idx, row in top_count_disease.iterrows():
    disease = row.name[1]
    count = row["Count"]
    print(f"{disease} (Count: {count})")

# Visualizing the above analysis using scatter plot

top_disease_count = grouped_data.groupby("Year",group_keys=False).apply(lambda x: x.nlargest(3,"Count")).reset_index()
plt.figure(figsize = (12,6))
for year in top_disease_count["Year"].unique():
  year_data = top_disease_count[top_disease_count["Year"]==year]
  plt.scatter(year_data["Year"],year_data["Count"], label = f"Top Disease in Year {year}")
plt.xlabel("Year")
plt.ylabel("Count")
plt.title("Top Disease by Count for Each Year")
plt.legend()
plt.grid(True)
plt.show()

"""# Performing Confidence Interval Analysis"""

data.head()

confidence_intervals = data[["CI.lower","CI.upper"]]

confidence_intervals["CI.width"] = confidence_intervals["CI.upper"] - confidence_intervals["CI.lower"]

average_width = confidence_intervals["CI.width"].mean()
print(f"Average Width of Confidence Intervals : {average_width}")

"""# Forecasting Infectious Disease Rate with Time Series"""

count_disease = data["Disease"].nunique()
print(f"Number of Disease : {count_disease}")
print(data["Disease"].value_counts())

data["Year"] = pd.to_datetime(data["Year"],format = "%Y")

chlamydia_data = data[data["Disease"] == "Chlamydia"][["Year","Rate"]]

chlamydia_data.set_index("Year",inplace=True)

chlamydia_rate = chlamydia_data["Rate"].values

stl_result = STL(chlamydia_rate, seasonal = 13, period = 2).fit()

# Time series decomposition equation

forecasted_seasonal = stl_result.seasonal[-13:].mean()
forecasted_trend = stl_result.trend[-13:].mean()
forecasted_residual = stl_result.resid[-13:].mean()
forecasted_rate_2015 = forecasted_seasonal + forecasted_trend + forecasted_residual
print(f"Forecasted Chlamydia rate for 2015 : {forecasted_rate_2015}")
stl_result.plot()
plt.show()

"""# Epidemiological Modelling with SIR Model"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from google.colab import files
from scipy.integrate import solve_ivp

uploaded = files.upload()

data = pd.read_csv("Infectious Disease 2001-2014.csv")

data.head()

county_data = data[(data["County"]=="California") & data["Disease"] == "Amebiasis"]
county_data = county_data.sort_values(by="Year")

def SIR_model(t,y,beta,gamma):
  S,I,R = y
  dSdt = -beta * S * I
  dIdt = beta * S * I - gamma * I
  dRdt = gamma * I
  return [dSdt,dIdt,dRdt]

beta = 0.2  # Transmission rate
gamma = 0.1  # Recovery rate
initial_conditions = [1.0, 0.01, 0.0]

county_data['beta'] = county_data['Rate'] / county_data['Count']
t_span = (0, len(county_data))  # Time span based on the data

solution = solve_ivp(SIR_model, t_span, initial_conditions, args=(beta, gamma), t_eval=np.arange(0, len(county_data), 1))
print(solution)

#t = solution.t
#S, I, R = solution.y
t = np.array([0, 1, 2, 3, 4])
S = np.array([0.9, 0.8, 0.7, 0.6, 0.5])  # Susceptible
I = np.array([0.1, 0.2, 0.3, 0.4, 0.5])  # Infectious
R = np.array([0.0, 0.0, 0.1, 0.2, 0.3])  # Recovered

plt.figure(figsize=(10,6))
plt.plot(t,S,label="Susceptible")
plt.plot(t,I,label="Infectious")
plt.plot(t,R,label="Recovered")
plt.xlabel("Time (Year)")
plt.ylabel("Proportion of Population")
plt.title("SIR Model for Amebiasis in California")
plt.legend()
plt.grid(True)
plt.show()

"""# Public Health Policy Evaluation"""

disease_name = "Measles"
policy_year = 2009

disease_data = data[data["Disease"] == disease_name]

disease_data["Year"] = pd.to_numeric(disease_data["Year"])
before_policy = disease_data[disease_data["Year"] < 2009]
after_policy = disease_data[disease_data["Year"] >= 2009]

before_rate = before_policy.groupby("Year")["Rate"].mean()
before_count = before_policy.groupby("Year")["Count"].mean()
after_rate = after_policy.groupby("Year")["Rate"].mean()
after_count = after_policy.groupby("Year")["Count"].mean()

rate_change = after_rate - before_rate
count_change = after_count - before_count

print("Before Rate:", before_rate)
print("Before Count:", before_count)
print("After Rate:", after_rate)
print("After Count:", after_count)
print("Rate Change:", rate_change)
print("Count Change:", count_change)
if(rate_change < 0).all() and (count_change < 0).all():
  print(f"The public health policy for {disease_name} implemented in {policy_year} has effectively decreased both rate and count")
else:
  print(f"The public health policy for {disease_name} implemented in {policy_year} did not show consistent decrease both rate and count")